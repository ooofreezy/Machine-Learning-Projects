# -*- coding: utf-8 -*-
"""Movie Recommendation System using Cosine Similarity

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DOaX-mDILY5FW8_1sLi0zA5EPXQ62war
"""

!pip install nltk scikit-learn numpy pandas -q

"""Importing the Dependencies"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from wordcloud import WordCloud
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

"""Understanding and Loading Data"""

# loading the dataset to a pandas dataframe
df = pd.read_csv("/content/movies.csv")

df.shape

df.head(2)

df.tail(2)

df.info()

#filtering the required columns for recommendation
required_columns = ["genres", "title", "keywords", "overview"]
df= df[required_columns]

df.shape

#checking for missing values
df.info()

#drop missing values in the columns
df = df.dropna().reset_index(drop=True)

df.info()

#now we combine information in all 3 columns
df['combined'] = df['genres']+ ' ' + df['keywords'] + ' ' + df['overview']

df.head()

df.tail()

data = df[['title', 'combined']]

data.head()

data.shape

#WordCloud for movie content
combined_text = " ".join(df['combined'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_text)

# Using wordcloud to visualise the most common words in the movie content
plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Most Common Words in Movie content")
plt.show()

# download nltk data
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))

def preprocess_text(text):
  # Remove special characters and numbers
  text = re.sub("[^a-zA-Z\s]", "", text)
  # convert to lowercase
  text = text.lower()
  # Tokenize and remove stopwords
  tokens = word_tokenize(text)
  tokens = [word for word in tokens if word not in stop_words]
  return " ".join(tokens)

# Apply preprocessing to the movie content
data['cleaned_text'] = df['combined'].apply(preprocess_text)

data.head()

# Vectorization with TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=5000)
tfidf_matrix = tfidf_vectorizer.fit_transform(data['cleaned_text'])

# Lets compute cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

print(cosine_sim[1])

# Recommendation Function
def recommend_movies(movie_name, cosine_sim=cosine_sim, df=data, top_n=5):
  # Find the index of the movie
  idx = df[df['title'].str.lower() == movie_name.lower()].index
  if len(idx) == 0:
    return "Movie not found in dataset!"
  idx = idx[0]

  # Get similarity scores
  sim_scores = list(enumerate(cosine_sim[idx]))
  sim_scores = sorted(sim_scores, key= lambda x: x[1], reverse=True)
  sim_scores = sim_scores[1:top_n+1]

  #Get movie indices
  movie_indices = [i[0] for i in sim_scores]

  # Return top n similar movies
  return df[['title']].iloc[movie_indices]

data['title']

#row_index = df[df['title'] == 'John Carter'].index
 row_index = df[df['title'] == 'Spectre'].index
 print(row_index)

movie_name = data['title'][2]
print(movie_name)

# Example Recommendation
print(f"Recommendations for the Movie{movie_name}")
recommendations = recommend_movies(movie_name)
print(recommendations)